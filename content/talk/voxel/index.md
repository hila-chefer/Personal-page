---
title: Leveraging Attention for Improved Accuracy and Robustness (English)
event: Voxel51- Computer Vision Meetup
event_url: 
location: Virtual
summary: This talk demonstrates how attention explainability can be used to improve model robustness and accuracy for image classification and generation tasks.
abstract: "In recent years, the naturally interpretable attention mechanism has become one of the most common building blocks of neural networks, allowing us to produce explanations intuitively and easily. However, the applications of such explanations beyond the scope of accountability and interpretability remain limited.

In this talk, Hila will present her latest research on leveraging attention to significantly improve the accuracy and robustness of state-of-the-art large neural networks with limited resources. This is achieved by directly manipulating the attention maps based on intuitive objectives and can be applied to a variety of tasks ranging from object classification to image generation.

Hila Chefer is a PhD student and lecturer at Tel-Aviv University, and an intern at Google research. Her research focuses on constructing faithful explainable AI algorithms, and leveraging explanations to promote model accuracy and robustness."

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: "2023-03-27T11:00:00Z"
date_end: "2023-03-27T12:00:00Z"
all_day: false

# Schedule page publish date (NOT talk date).
publishDate: "2022-08-04T00:00:00Z"

authors: ["Hila Chefer"]
tags: ["Attention","Explainability","ViT","Stable Diffusion"]

# Is this a featured talk? (true/false)
featured: false

image:
  caption:
  focal_point: Right

links:
#- icon: twitter
#  icon_pack: fab
#  name: Follow
#  url: https://twitter.com/georgecushen
url_code: ""
url_pdf: ""
url_slides: ""
url_video: "https://www.youtube.com/watch?v=QYXIHIvesYo"

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: 

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects:
# - internal-project

# Enable math on this page?
math: true
---

{{% alert note %}}
Click on the **Slides** button above to view the built-in slides feature.
{{% /alert %}}
