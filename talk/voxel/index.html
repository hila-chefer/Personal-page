<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academia 4.3.1"><meta name=generator content="Hugo 0.115.0"><meta name=author content="Hila Chefer"><meta name=description content="This talk demonstrates how attention explainability can be used to improve model robustness and accuracy for image classification and generation tasks."><link rel=alternate hreflang=en-us href=https://examplesite.org/talk/voxel/><meta name=theme-color content="#b54845"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin=anonymous><link rel=stylesheet href=https://use.fontawesome.com/releases/v5.6.0/css/all.css integrity=sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css crossorigin=anonymous title=hl-light><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css crossorigin=anonymous title=hl-dark disabled><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Lato:400,700|Open+Sans|Roboto+Mono&display=swap"><link rel=stylesheet href=/css/academia.min.d1d8d530dfa7b55780d5887faa05b19b.css><link rel=manifest href=/site.webmanifest><link rel=icon type=image/png href=/img/icon.png><link rel=apple-touch-icon type=image/png href=/img/icon-192.png><link rel=canonical href=https://examplesite.org/talk/voxel/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@hila_chefer"><meta property="twitter:creator" content="@hila_chefer"><meta property="og:site_name" content="Hila Chefer"><meta property="og:url" content="https://examplesite.org/talk/voxel/"><meta property="og:title" content="Leveraging Attention for Improved Accuracy and Robustness (English) | Hila Chefer"><meta property="og:description" content="This talk demonstrates how attention explainability can be used to improve model robustness and accuracy for image classification and generation tasks."><meta property="og:image" content="https://examplesite.org/img/icon-192.png"><meta property="twitter:image" content="https://examplesite.org/img/icon-192.png"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2022-08-04T00:00:00+00:00"><meta property="article:modified_time" content="2023-03-27T11:00:00+00:00"><title>Leveraging Attention for Improved Accuracy and Robustness (English) | Hila Chefer</title></head><body id=top data-spy=scroll data-target=#TableOfContents data-offset=71><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id=navbar-main><div class=container><a class=navbar-brand href=/>Hila Chefer</a>
<button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar aria-controls=navbar aria-expanded=false aria-label="Toggle navigation"><span><i class="fas fa-bars"></i></span></button><div class="collapse navbar-collapse" id=navbar><ul class="navbar-nav ml-auto"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#talks><span>Talks</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Blog</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li><li class=nav-item><a class="nav-link js-dark-toggle" href=#><i class="fas fa-moon" aria-hidden=true></i></a></li></ul></div></div></nav><div class="pub py-5" itemscope itemtype=http://schema.org/Event><div class="article-container py-3"><h1 itemprop=name>Leveraging Attention for Improved Accuracy and Robustness (English)</h1><meta content="2023-03-27 11:00:00 +0000 UTC" itemprop=datePublished><meta content="2023-03-27 11:00:00 +0000 UTC" itemprop=dateModified><div class=article-metadata><div><span itemprop="author name" itemtype=http://schema.org/Person><a href=/authors/hila-chefer/>Hila Chefer</a></span></div></div><div class="btn-links mb-3"><a class="btn btn-outline-primary my-1 mr-1" href="https://www.youtube.com/watch?v=QYXIHIvesYo" target=_blank rel=noopener>Video</a></div></div></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract itemprop=text>In recent years, the naturally interpretable attention mechanism has become one of the most common building blocks of neural networks, allowing us to produce explanations intuitively and easily. However, the applications of such explanations beyond the scope of accountability and interpretability remain limited. In this talk, Hila will present her latest research on leveraging attention to significantly improve the accuracy and robustness of state-of-the-art large neural networks with limited resources. This is achieved by directly manipulating the attention maps based on intuitive objectives and can be applied to a variety of tasks ranging from object classification to image generation.</p><div class=row><div class="col-md-10 mx-auto"><div class=row><div class="col-12 col-md-3 pub-row-heading">Date</div><div class="col-12 col-md-9" itemprop=datePublished>Mar 27, 2023<div class=talk-time>11:00
&mdash; 12:00</div></div></div></div></div><div class="d-md-none space-below"></div><div class=row><div class="col-md-10 mx-auto"><div class=row><div class="col-12 col-md-3 pub-row-heading">Event</div><div class="col-12 col-md-9">Voxel51- Computer Vision Meetup</div></div></div></div><div class="d-md-none space-below"></div><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Location</div><div class="col-12 col-md-9">Virtual</div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tags/attention/>Attention</a>
<a class="badge badge-light" href=/tags/explainability/>Explainability</a>
<a class="badge badge-light" href=/tags/vit/>ViT</a>
<a class="badge badge-light" href=/tags/stable-diffusion/>Stable Diffusion</a></div><div class="media author-card" itemscope itemtype=http://schema.org/Person><div class=media-body><h5 class=card-title itemprop=name><a href=/authors/hila-chefer/></a></h5><ul class=network-icon aria-hidden=true></ul></div></div></div></div><script src=/js/mathjax-config.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin=anonymous></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin=anonymous async></script>
<script>hljs.initHighlightingOnLoad()</script><script src=/js/academia.min.6c2ba2801d406881b3c2277043cedd76.js></script><div class=container><footer class=site-footer><div class=container><div class="row align-items-center"><div class="col-md-6 mb-4 mb-md-0"><p class=mb-0>Copyright Â© 2023 &#183;
Powered by
<a href=https://gethugothemes.com target=_blank rel=noopener>Gethugothemes</a></p></div><div class=col-md-6><ul class="list-inline network-icon text-right mb-0"><li class=list-inline-item><a href=https://github.com/hila-chefer target=_blank rel=noopener title=Github><i class="fab fa-github" aria-hidden=true></i></a></li><li class=list-inline-item><a href="https://scholar.google.com/citations?user=B8sA9JoAAAAJ&amp;hl=en" target=_blank rel=noopener title="Google Scholar"><i class="ai ai-google-scholar" aria-hidden=true></i></a></li><li class=list-inline-item><a href=https://www.semanticscholar.org/author/Hila-Chefer/2038268012 target=_blank rel=noopener title="Semantic Scholar"><i class="ai ai-semantic-scholar" aria-hidden=true></i></a></li><li class=list-inline-item><a href=https://twitter.com/hila_chefer target=_blank rel=noopener title=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li class=list-inline-item><a href=https://www.linkedin.com/in/hila-chefer target=_blank rel=noopener title=LinkedIn><i class="fab fa-linkedin" aria-hidden=true></i></a></li></ul></div></div></div></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>