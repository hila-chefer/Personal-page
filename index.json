[{"authors":["admin"],"categories":null,"content":"I am a Ph.D. Candidate at Tel Aviv University, working in the Deep Learning Lab under the supervision of Prof. Lior Wolf.\nMy main interests are computer vision, NLP, and multi-modal learning. My research is mostly focused on attention-based models and explainable-AI.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://examplesite.org/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Ph.D. Candidate at Tel Aviv University, working in the Deep Learning Lab under the supervision of Prof. Lior Wolf.\nMy main interests are computer vision, NLP, and multi-modal learning. My research is mostly focused on attention-based models and explainable-AI.","tags":null,"title":"Hila Chefer","type":"authors"},{"authors":["Hila Chefer"],"categories":null,"content":"","date":1641301200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641301200,"objectID":"21c6ecfbe0b616c0ee72c70cba9e9550","permalink":"https://examplesite.org/talk/microsoft-01-2022/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/talk/microsoft-01-2022/","section":"talk","summary":"This talk takes a deep dive into the attention mechanism. During the talk, we review the motivations and applications of the self-attention mechanism. Additionally, we review the main building blocks for self-attention explainability and some cool applications of Transformer-explainability from recent research.","tags":["Transformers","Explainability"],"title":"Intro to Transformers and Transformer Explainability (English)","type":"talk"},{"authors":["Hila Chefer"],"categories":null,"content":"","date":1635253200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635253200,"objectID":"7dc6a0f54f913072d15ff389d3c00789","permalink":"https://examplesite.org/talk/imvc-10-2021/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/talk/imvc-10-2021/","section":"talk","summary":"This talk explores the main milestones in Transformer-based research, and Transformer explainability research.","tags":["Transformers","Explainability"],"title":"Transformer Explainability (English)","type":"talk"},{"authors":["Hila Chefer"],"categories":null,"content":"Talk starts from 1:00:00.\n","date":1634734800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634734800,"objectID":"d26cfd9c3bd10295a0842a7f50405270","permalink":"https://examplesite.org/talk/ibm-10-2021/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/talk/ibm-10-2021/","section":"talk","summary":"This talk explores the main milestones in Transformer-based research, and Transformer explainability research.","tags":["Transformers","Explainability"],"title":"Transformer Explainability (Hebrew)","type":"talk"},{"authors":["Hila Chefer","Sagie Benaim","Roni Paiss","Lior Wolf"],"categories":null,"content":"","date":1634688e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1634688e3,"objectID":"b4c2f5511324fc0e944001e26f1c128d","permalink":"https://examplesite.org/publication/clip-guided-essence-transfer/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/clip-guided-essence-transfer/","section":"publication","summary":"This paper proposes a novel method to transfer the semantic essence from a target image to a source image, without changing the identity of the source. The method uses CLIP's image latent space, which is more stable and expressive than the textual latent space.","tags":["Transformers","CLIP","StyleGAN","Essence Transfer"],"title":"Image-Based Clip-Guided Essence Transfer","type":"publication"},{"authors":["Hila Chefer","Shir Gur","Lior Wolf"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"5568b0b8ab8b6a1b55d2594b6aea97a4","permalink":"https://examplesite.org/publication/generic-attention-model-explainability/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/generic-attention-model-explainability/","section":"publication","summary":"The paper presents an interpretability method for all types of attention, including bi-modal Transformers and encoder-decoder Transformers. The method achieves SOTA results for CLIP, DETR, LXMERT, and more.","tags":["Explainability","Transformers","CLIP","DETR","LXMERT","VisualBERT","Cross-Attention","Encoder-Decoder"],"title":"Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers (Oral)","type":"publication"},{"authors":["Hila Chefer"],"categories":null,"content":"","date":1626008400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626008400,"objectID":"0d721532b10d89706f210ab04b1c5e32","permalink":"https://examplesite.org/talk/w-ai-07-2021/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/talk/w-ai-07-2021/","section":"talk","summary":"This talk is an intro talk to DNNs and attention, targeted at DL beginners. The talk was given as part of a volunteering program to encourage women to consider research in the deep learning field.","tags":["Attention","Deep Learning","Introduction"],"title":"Attention in Deep Learning (Hebrew)","type":"talk"},{"authors":["Hila Chefer","Shir Gur","Lior Wolf"],"categories":null,"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"3e8be47ef8c0c5e42b992ad36333fb33","permalink":"https://examplesite.org/publication/transformer-interpretability/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/transformer-interpretability/","section":"publication","summary":"This paper presents an interpretability method for self-attention based models, and specifically for Transformer encoders. The method incorporates LRP and gradients, and achieves SOTA results for ViT, BERT, and DeiT.","tags":["Explainability","Transformers","ViT","BERT","Self-Attention"],"title":"Transformer Interpretability Beyond Attention Visualization","type":"publication"}]